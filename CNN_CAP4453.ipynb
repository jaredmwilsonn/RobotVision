{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part A"
      ],
      "metadata": {
        "id": "Fw_uAxZgUPol"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYOv0gViTqHU",
        "outputId": "2ae5ba26-0cac-4ea4-b1db-6776a2240c1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                16010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,826\n",
            "Trainable params: 34,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "422/422 [==============================] - 3s 7ms/step - loss: 0.3672 - accuracy: 0.8868 - val_loss: 0.0869 - val_accuracy: 0.9742\n",
            "Epoch 2/2\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.1184 - accuracy: 0.9634 - val_loss: 0.0615 - val_accuracy: 0.9845\n",
            "Test loss: 0.06199943274259567\n",
            "Test accuracy: 0.9811000227928162\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = keras.Sequential(\n",
        "  [\n",
        "    keras.Input(shape=input_shape),\n",
        "    layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes, activation=\"softmax\"),\n",
        "  ]\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "# TRAIN THE MODEL\n",
        "batch_size = 128\n",
        "epochs = 2\n",
        "np.random.seed(0)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", \n",
        "metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, \n",
        "validation_split=0.1)\n",
        "\n",
        "# EVALUATE THE MODEL\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part B"
      ],
      "metadata": {
        "id": "kQnbjTZuUXkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = keras.Sequential(\n",
        "  [\n",
        "    keras.Input(shape=input_shape),\n",
        "    # Create a convolution neural network (with 30 channels) with relu activation function and with kernel of size (5,5)\n",
        "    layers.Conv2D(30, kernel_size=(5, 5), activation=\"relu\"),\n",
        "    # MaxPooling for 2D with a pool size of (2,2)\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    # Create a convolution neural network (with 15 channels) with relu activation function and with kernel of size (3,3)\n",
        "    layers.Conv2D(15, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    # MaxPooling for 2D with a pool size of (2,2)\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    # Dropout layer with a probability of 20%\n",
        "    layers.Dropout(0.2),\n",
        "    # Flatten layer\n",
        "    layers.Flatten(),\n",
        "    # Densely connected neural network with 128 output neurons and with relu activation function\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    # Densely connected neural network with 50 output neurons and with relu activation function\n",
        "    layers.Dense(50,activation='relu'),\n",
        "    # Densely connected neural network with 10 output neurons and with softmax activation function\n",
        "    layers.Dense(10, activation='softmax')\n",
        "  ]\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "# TRAIN THE MODEL\n",
        "batch_size = 128\n",
        "epochs = 2\n",
        "np.random.seed(0)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", \n",
        "metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, \n",
        "validation_split=0.1)\n",
        "\n",
        "# EVALUATE THE MODEL\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjLO5osNUbUt",
        "outputId": "4c166007-a256-4fe9-8b3d-fca81dfdffe9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 24, 24, 30)        780       \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 12, 12, 30)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 10, 10, 15)        4065      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 5, 5, 15)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 5, 5, 15)          0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 375)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               48128     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 50)                6450      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 10)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 59,933\n",
            "Trainable params: 59,933\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "422/422 [==============================] - 3s 7ms/step - loss: 0.4519 - accuracy: 0.8541 - val_loss: 0.0812 - val_accuracy: 0.9790\n",
            "Epoch 2/2\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1458 - accuracy: 0.9545 - val_loss: 0.0565 - val_accuracy: 0.9853\n",
            "Test loss: 0.05415014550089836\n",
            "Test accuracy: 0.983299970626831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model A:\n",
        "  Test accuracy: 0.9811000227928162\n",
        "\n",
        "Model B:\n",
        "  Test accuracy: 0.9837999939918518\n",
        "\n",
        "Model B gives better accuracy. This is a combination of Model B having: \n",
        "\n",
        "*   an overall higher quantity of layer\n",
        "*   a smaller rate in the dropout layer (0.2 vs 0.5)\n",
        "*   multiple dense layers directly before the output\n",
        "*   more trainable parameters\n"
      ],
      "metadata": {
        "id": "aWk-RPwuWgoZ"
      }
    }
  ]
}